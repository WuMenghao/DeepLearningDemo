# 第6章 人脸检测和人脸识别

人脸检测(`Face Detection`)和人脸识别技术是深度学习的重要应用之一。本章首先
会介绍 MTCNN 算法的原理，它是基于卷积神经网络的一种高精度的实时人脸检测
和对齐技术。接着，还会介绍如何利用深度卷积网络提取人脸特征，以及如何利用
提取的特征进行人脸识别。最后会介绍如何在TensorFlow中实践上述的算法。

## 6.1 MTCNN 的原理

搭建人脸识别系统的第一步是人脸检测，也就是在图片中找到人脸的位置。在这个过
程中，系统的输入是一张可能含有人脸的图片，输出是人脸位置的矩形框。一般来说，
人脸检测应该可以正确检测出图片中存在的所有人脸，不能遗漏，也不能错检。

获得包含人脸的矩形框后，第二部要做的是人脸对齐(`Face Alignment`)。原始图片中
人脸的姿态、位置可能有较大的区别，为了之后统一处理，要把人脸"摆正"。为此，
需要检测人脸中的关键点(`Landmark`),如眼睛的位置、鼻子的位置、嘴巴的位置、脸的
位置、脸的轮廓等。根据这些关键点可以使用仿射变换将人脸统一校准，以尽量消除
姿势不同带来的误差。

这里介绍一种基于深度卷积神经网络的人脸检测和人脸对齐方法——`MTCNN`。MT是英
文单词`Multi-task`的简写，意即这种方法可以同时完成人脸检测和人脸对齐两项任务
。 相比于传统方法，MTCNN的性能更好，可以更精确地走位人脸；此外，MTCNN也可
以做到实时的检测。

MTCNN由三个神经网络组成，分别是P-Net、 R-Net、 0-Net。在使用这些网络之前，
首先要将原始图片缩放到不同尺度， 形成一个“图像金字塔”。接着会对每个尺度
的图片通过神经网络计算一遍。这样做的原因在于：原始图片中的人脸存在不同的尺
度，如奇的人脸比较大，有的人脸比较小。对于比较小的人脸，可以在放大后的图片
上检测；对于比较大的人脸，可以在缩小后的国片上检测。这样，就可以在统一的
尺度下检测人脸了。

**P-Net**

现在再来讨论第一个网络`P-Net`的结构,`P-Net`的输入是一个宽和高皆为`12像素`，
同时是3通道的RGB图像，该网络要判断这个`12x12`的图像中是否含有人脸，并且给出
人脸框相关键点的位置。因此，对应的输出由三部分组成：

> * 第一个部分要判断该图像是否是人脸（`face classification` ) ,输出向量的形
    状为`lxlx2`，也就是两个值，分别为该图像是人脸的概率，以及该图像不是人脸
    的概率。这两个值加起来应该严格等于`l`。之所以使用两个值来表示，是为了方
    便定义交叉烟损失。
> * 第二个部分给出框的精确位置（`boundingbox regression`),一般称之
   为框回归。P-Net输入的`12×12`的图像块可能并不是完美的人脸框的位置，如
   高的时候人脸并不正好为方形，有的时候`12×l2`的图像块可能偏左或偏右，因
   此需要输出当前框位置相对于完美的人脸框位置 的偏移。 这个偏移由四个变量组
   成。一般地， 对于圄像中的框，可以用四个数来表示E自由位置：框左上角的横坐
   标、框左上角的纵坐标、框的宽度、 框的高度。 因此，框回归输出的值是：框左
   上角的横坐标的中目对偏移、框左上角的纵坐标的相对偏移、 框的宽度的误差、
   框的高度的误差。 输出向量的形状就是圄中的`1×l×4`
> * 第三个部分给出人脸的5个关键点的位置(`Facial landmark localization`)。`5`
    个关键点分别为：左眼的位置、右眼的位置、鼻子的位置、左嘴角的位置、右嘴
    角的位置。每个关键点又需要横坐标和纵坐标两维来表示，因此输出一共是10维
    （即`l×l×10`） 。
 
图中框的大小各高不同， 除了框回归的影响外， 主要是因为将图片金字塔中的各个
尺度都使用P-Net计算了一遍， 因此形成了大小不同的人脸框。P-Net的结果还是比较
粗糙的， 所以接下来又使用R-Net进一步调优。 

**R-Net 、O-Net**

`R-Net`的网络结构与之前的P-Net 非常类似， P-Net的输入是`12×12×3`的图像，
R-Net是`24×24`心的图像，也就是说，R-Net 判断`24×24×3`的图像中是否含有人脸，
以及预测关键点的位置。R-Net的输出和P-Net完全一样，同样由人脸判别、 框回归、
 关键点位置预测三部分组成。
 
在实际应用中，对每个`P-Net`输出可能为人脸的区域都放缩到`24×24`的大小，再输入到
`R-Net`中，进行进一步判定。显然R-Net消除了P-Net中很多误判的情况。

进一步把所高得到的区域缩放成`48×48`的大小，输入到最后的`O-Net`中，O-Net的结构同
样与P-Net类似，不同点在于宫的输入是`48×48×3`的图像，网络的通道数和层数也更多了。

从`P-Net`到`R-Net`，最后再到`O-Net`，网络输入的图片越来越大，卷积层的通道数越
来越多，内部的层数也越来越多， 因此官们识别人脸的准确率应该是越来越高的。 同时
，`P-Net`的运行速度是最快的， `R-Net`的速度其次，`O-Net`的运行速度最慢。 之所
以要使用三个网络，是因为如果一开始直接对图中的每个区域使用`O-Net`， 速度会非常
慢。实际上`P-Net`先做了一遍过滤，将过滤后的结果再交给`R-Net`进行过滤，最后将过滤
后的结果交给效果最好但速度较慢的`O-Net`进行判别。这样在每一步都提前减少了需要判
别的数量，有效降低了处理时间。 
***
最后介绍`MTCNN`的`损失定义`和`训练过程`。 MTCNN中每个网络都有三部分输出，因此
损失也由三部分组成。 针对`人脸判别部分`，直接使用`交叉熵损失`，针对`框回归和
关键点判定`，直接使用`L2损失`。 最后这三部分损失各自乘以自身的权重再加起来，
就形成最后的总损失了。在`训练P-Net和R-Net`时，更关心`框位置的准确性`，而较少关注
`关键点判定的损失`，因此关键点判定损失的`权重很小`。对于`0-Net`，`关键点判定损失的
权重较大`。